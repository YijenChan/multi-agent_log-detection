解析代码来源于github项目[GitHub - zzkluck/EasyLog: 高敏捷高性能的日志解析/日志模板提取工具](https://github.com/zzkluck/EasyLog)

基于正则替换的高效解析/日志模板提取

### 文件介绍

#### 主解析文件logParser_main.py

输入示例：BGL.log
输出示例：BGL.log_structured.csv、BGL.log_template.csv、log_parser.log

配置参数在代码开头default_running_settings中

输入文件默认为log格式**({dataset_name}.log)**，

函数transform_log_to_csv分块处理（设定20w行为一块）log文件，将日志切割结构化，添加上用户（手动）在配置中自定义的headers表头

transform_log_to_csv函数在分块处理流程中调用核心解析函数parse_line流式解析日志，提取每行日志模板，进行事件分类，总结模板到文件{dataset_name}.log_template.csv中

#### 规则配置文件settings.py

包含了loghub项目下数据集的一些默认解析规则，对于BGL和HDFS日志进一步添加了部分处理配置参数（表头、标签值、规则正则等）

#### HDFS数据集标签化处理文件HDFS_label.py、find_abnormal.py

HDFS_label.py依据官方给出标签anomaly_label.csv给上面处理好的结构化数据打上Label标签列，由于原始的标签数据量过大（50w），用了一个小脚本挑出了异常的标签，其余的都认为正常

find_abnormal.py过滤下数据集给出的标签文件，仅留下非正常的日志ID

#### 采样脚本logSample_tqdm.py

依据处理好的标签数据集采样，使用动态规划算法调整异常or正常样本采样数目


### 采样结果

BGL模板（log key）数量：600

BGL异常样本数量: 348460

HDFS模板数量：52

HDFS异常样本数量：288250

事件分布统计在log_parser.log文件中
